---
redirect_from:
  - "/model/spvcm/using-the-sampler"
interact_link: content/model/spvcm/using_the_sampler.ipynb
kernel_name: ana
kernel_path: content/model/spvcm
has_widgets: false
title: |-
  using_the_sampler
pagenum: 53
prev_page:
  url: /model/spvcm/spatially-varying-coefficients.html
next_page:
  url: /model/spreg/intro.html
suffix: .ipynb
search: level model state variance models upper parameter sampling chain sampler lower spvcm x rho spatial psi matrix py components covariance values delta z also membership trace self lambda w diagnostics prior n p error configuration functions sample priors using both used beta mathbf package options stored iteration configs none sigma where function average should vector m weights run r steps parameters scale correlated contains sma y region get times same varying intercept data its variable set working mcmc value starting se addition any rate nsamples only effects samples object coda python few example means between want draw config class njobs

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">using_the_sampler</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Using-the-sampler">Using the sampler<a class="anchor-link" href="#Using-the-sampler"> </a></h1><p><code>spvcm</code> is a generic gibbs sampling framework for spatially-correlated variance components models. The current supported models are:</p>
<ul>
<li><code>spvcm.both</code> contains specifications with correlated errors in both levels, with the first statement <code>se/sma</code> describing the lower level and the second statement <code>se/sma</code> describing the upper level. In addition, <code>MVCM</code>, the multilevel variance components model with no spatial correlation, is in the <code>both</code> namespace. </li>
<li><code>spvcm.lower</code> contains two specifications, <code>se/sma</code>, that can be used for a variance components model with correlated lower-level errors.</li>
<li><code>spvcm.upper</code> contains two specifications, <code>se/sma</code> that can be used for a variance components model with correlated upper-level errors. </li>
</ul>
<h3 id="Specification">Specification<a class="anchor-link" href="#Specification"> </a></h3><p>These derive from a variance components specification:</p>
$$ Y \sim \mathcal{N}(X\beta, \Psi_1(\lambda, \sigma^2) + \Delta\Psi_2(\rho, \tau^2)\Delta') $$<p>Where:</p>
<ol>
<li>$\beta$, called <code>Betas</code> in code, is the marginal effect parameter. In this implementation, any region-level covariates $Z$ get appended to the end of $X$. So, if $X$ is $n \times p$ ($n$ observations of $p$ covariates)  and $Z$ is $J \times p'$ ($p'$ covariates observed for $J$ regions), then the model's $X$ matrix is $n \times (p + p')$ and $\beta$ is $p + p' \times 1$. </li>
<li>$\Psi_1$ is the covariance function for the response-level model. In the software, a separable covariance is assumed, so that $\Psi_1(\rho, \sigma^2) = \Psi_1(\rho) * I \sigma^2)$, where $I$ is the $n \times n$ covariance matrix. Thus, $\rho$ is the spatial autoregressive parameter and $\sigma^2$ is the variance parameter. In the software, $\Psi_1$ takes any of the following forms:<ul>
<li>Spatial Error (<code>SE</code>): $\Psi_1(\rho) = [(I - \rho \mathbf{W})'(I - \rho \mathbf{W})]^{-1} \sigma^2$</li>
<li>Spatial Moving Average (<code>SMA</code>): $\Psi_1(\rho) = (I + \rho \mathbf{W})(I + \lambda \mathbf{W})'$</li>
<li>Identity: $\Psi_1(\rho) = I$</li>
</ul>
</li>
<li>$\Psi_2$ is the region-level covariance function, with region-level autoregressive parameter $\lambda$ and region-level variance $\tau^2$. It has the same potential forms as $\Psi_1$. </li>
<li>$\alpha$, called <code>Alphas</code> in code, is the region-level random effect. In a variance components model, this is interpreted as a random effect for the upper-level. For a Varying-intercept format, this random component should be added to a region-level fixed effect to provide the varying intercept. This may also make it more difficult to identify the spatial parameter. </li>
</ol>
<h2 id="Softare-implementation">Softare implementation<a class="anchor-link" href="#Softare-implementation"> </a></h2><p>All of the possible combinations of Spatial Moving Average and Spatial Error processes are contained in the following classes. I will walk through estimating one below, and talk about the various features of the package.</p>
<p>First, the API of the package is defined by the <code>spvcm.api</code> submodule. To load it, use <code>import spvcm.api as spvcm</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">spvcm</span> <span class="k">as</span> <span class="nn">spvcm</span> <span class="c1">#package API</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">Generic</span> <span class="c1"># abstract customizable class, ignores rho/lambda, equivalent to MVCM</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">MVCM</span> <span class="c1"># no spatial effect</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">SESE</span> <span class="c1">#  both spatial error (SE)</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">SESMA</span> <span class="c1"># response-level SE, region-level spatial moving average</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">SMASE</span> <span class="c1"># response-level SMA, region-level SE</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">SMASMA</span> <span class="c1"># both levels SMA</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SE</span> <span class="c1"># response-level uncorrelated, region-level SE</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span> <span class="c1"># response-level uncorrelated, region-level SMA</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">lower_level</span><span class="o">.</span><span class="n">Lower_SE</span> <span class="c1"># response-level SE, region-level uncorrelated</span>
<span class="n">spvcm</span><span class="o">.</span><span class="n">lower_level</span><span class="o">.</span><span class="n">Lower_SMA</span> <span class="c1"># response-level SMA, region-level uncorrelated </span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/lw17329/Dropbox/dev/spvcm/spvcm/abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.
  from .sqlite import head_to_sql, start_sql
/home/lw17329/anaconda/envs/ana/lib/python3.6/site-packages/pysal/__init__.py:65: VisibleDeprecationWarning: PySAL&#39;s API will be changed on 2018-12-31. The last release made with this API is version 1.14.4. A preview of the next API version is provided in the `pysal` 2.0 prelease candidate. The API changes and a guide on how to change imports is provided at https://pysal.org/about
  ), VisibleDeprecationWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>spvcm.lower_level.sma.model.Lower_SMA</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Depending on the structure of the model, you need at least:</p>
<ul>
<li><code>X</code>, data at the response (lower) level</li>
<li><code>Y</code>, system response in the lower level</li>
<li><code>membership</code> or <code>Delta</code>, the membership vector relating each observation to its group or the "dummy variable" matrix encoding the same information. </li>
</ul>
<p>Then, if spatial correlation is desired, <code>M</code> is the "upper-level" weights matrix and <code>W</code> the lower-level weights matrix.</p>
<p>Any upper-level data should be passed in $Z$, and have $J$ rows. To fit a varying-intercept model, include an identity matrix in $Z$. You can include state-level and response-level intercept terms simultaneously.</p>
<p>Finally, there are many configuration and tuning options that can be passed in at the start, or assigned after the model is initialized.</p>
<p>First, though, let's set up some data for a model on southern counties predicting <code>HR90</code>, the Homicide Rate in the US South in 1990, using the the percent of the labor force that is unemployed (<code>UE90</code>), a principal component expressing the population structure (<code>PS90</code>), and a principal component expressing resource deprivation.</p>
<p>We will also use the state-level average percentage of families below the poverty line and the average Gini coefficient at the state level for a $Z$ variable.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#seaborn is required for the traceplots</span>
<span class="kn">import</span> <span class="nn">pysal</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Reading in the data, we'll extract these values we need from the dataframe.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">pdio</span><span class="o">.</span><span class="n">read_files</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">get_path</span><span class="p">(</span><span class="s1">&#39;south.shp&#39;</span><span class="p">))</span>
<span class="n">gdf</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">get_path</span><span class="p">(</span><span class="s1">&#39;south.shp&#39;</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">STATE_NAME</span> <span class="o">!=</span> <span class="s1">&#39;District of Columbia&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;UE90&#39;</span><span class="p">,</span> <span class="s1">&#39;PS90&#39;</span><span class="p">,</span> <span class="s1">&#39;RD90&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;STATE_NAME&#39;</span><span class="p">)[[</span><span class="s1">&#39;FP89&#39;</span><span class="p">,</span> <span class="s1">&#39;GI89&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>
<span class="n">J</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">HR90</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we'll construct some queen contiguity weights from the files to show how to run a model.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W2</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">queen_from_shapefile</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">get_path</span><span class="p">(</span><span class="s1">&#39;us48.shp&#39;</span><span class="p">),</span> 
                             <span class="n">idVariable</span><span class="o">=</span><span class="s1">&#39;STATE_NAME&#39;</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">w_subset</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">STATE_NAME</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span> <span class="c1">#only keep what&#39;s in the data</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">queen_from_shapefile</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">get_path</span><span class="p">(</span><span class="s1">&#39;south.shp&#39;</span><span class="p">),</span>
                             <span class="n">idVariable</span><span class="o">=</span><span class="s1">&#39;FIPS&#39;</span><span class="p">)</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">w_subset</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">FIPS</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span> <span class="c1">#again, only keep what&#39;s in the data</span>

<span class="n">W1</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span>
<span class="n">W2</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With the data, upper-level weights, and lower-level weights, we can construct a membership vector <em>or</em> a dummy data matrix. For now, I'll create the membership vector.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">membership</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">STATE_NAME</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">W2</span><span class="o">.</span><span class="n">id_order</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">values</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But, we could also build the dummy variable matrix using <code>pandas</code>, if we have a suitable categorical variable:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Delta_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">STATE_NAME</span><span class="p">)</span>
<span class="n">Delta</span> <span class="o">=</span> <span class="n">Delta_frame</span><span class="o">.</span><span class="n">values</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Every call to the sampler is of the following form:</p>
<p><code>sampler(Y, X, W, M, Z, membership, Delta, n_samples, **configuration)</code></p>
<p>Where <code>W</code>, <code>M</code> are passed if appropriate, <code>Z</code> is passed if used, and only one of <code>membership</code> or <code>Delta</code> is required. In the end, <code>Z</code> is appended to <code>X</code>, so the effects pertaining to the upper level will be at the tail end of the $\beta$ effects vector. If both <code>Delta</code> and <code>membership</code> are supplied, they're verified against each other to ensure that they agree before they are used in the model.</p>
<p>For all models, the membership vector or an equivalent dummy variable matrix is required. For models with correlation in the upper level, only the upper-level weights matrix $\mathbf{M}$ is needed. For lower level models, the lower-level weights matrix $\mathbf{W}$ is required. For models with correlation in both levels, both $\mathbf{W}$ and $\mathbf{M}$ are required.</p>
<p>Every sampler uses, either in whole or in part, <code>spvcm.both.generic</code>, which implements the full generic sampler discussed in the working paper. For efficiency, the upper-level samplers modify this runtime to avoid processing the full lower-level covariance matrix.</p>
<p>Like many of the <code>R</code> packages dedicated to bayesian models, configuration occurs by passing the correct dictionary to the model call. In addition, you can "setup" the model, configure it, and then run samples in separate steps.</p>
<p>The most common way to call the sampler is something like:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                    <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                    <span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                                    <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">tuning</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
                                                 <span class="n">adapt_step</span><span class="o">=</span><span class="mf">1.01</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 5000/5000 [00:15&lt;00:00, 317.80it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This model, <code>spvcm.upper_level.Upper_SMA</code>, is a variance components/varying intercept model with a state-level SMA-correlated error.</p>
<p>Thus, there are only five parameters in this model, since $\rho$, the lower-level autoregressive parameter, is constrained to zero:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">varnames</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Alphas&#39;, &#39;Betas&#39;, &#39;Sigma2&#39;, &#39;Tau2&#39;, &#39;Lambda&#39;]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The results and state of the sampler are stored within the <code>vcsma</code> object. I'll step through the most important parts of this object.</p>
<h1 id="trace"><code>trace</code><a class="anchor-link" href="#trace"> </a></h1><p>The quickest way to get information out of the model is via the trace object. This is where the results of the tracked parameters are stored each iteration. Any variable in the sampler state can be added to the tracked params. Trace objects are essentially dictionaries with the keys being the name of the tracked parameter and the values being a list of each iteration's sampler output.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">varnames</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Alphas&#39;, &#39;Betas&#39;, &#39;Sigma2&#39;, &#39;Tau2&#39;, &#39;Lambda&#39;]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this case, <code>Lambda</code> is the upper-level moving average parameter, <code>Alphas</code> is the vector of correlated group-level random effects, <code>Tau2</code> is the upper-level variance, <code>Betas</code> are the marginal effects, and <code>Sigma2</code> is the lower-level error variance.</p>
<p>I've written two helper functions for working with traces. First is to just dump all the output into a pandas dataframe, which makes it super easy to do work on the samples, or write them out to <code>csv</code> and assess convergence in R's <code>coda</code> package.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trace_dataframe</span> <span class="o">=</span> <span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>the dataframe will have columns containing the elements of the parameters and each row is a single iteration of the sampler:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trace_dataframe</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sigma2</th>
      <th>Tau2</th>
      <th>Lambda</th>
      <th>Alphas_0</th>
      <th>Alphas_1</th>
      <th>Alphas_2</th>
      <th>Alphas_3</th>
      <th>Alphas_4</th>
      <th>Alphas_5</th>
      <th>Alphas_6</th>
      <th>...</th>
      <th>Alphas_12</th>
      <th>Alphas_13</th>
      <th>Alphas_14</th>
      <th>Alphas_15</th>
      <th>Betas_0</th>
      <th>Betas_1</th>
      <th>Betas_2</th>
      <th>Betas_3</th>
      <th>Betas_4</th>
      <th>Betas_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>31.233393</td>
      <td>0.923435</td>
      <td>-0.047215</td>
      <td>-1.261656</td>
      <td>-0.736935</td>
      <td>-0.399375</td>
      <td>-0.034331</td>
      <td>-2.236596</td>
      <td>-1.213818</td>
      <td>-0.568231</td>
      <td>...</td>
      <td>0.106951</td>
      <td>1.516595</td>
      <td>-1.364607</td>
      <td>2.041536</td>
      <td>10.531876</td>
      <td>-0.483666</td>
      <td>2.109549</td>
      <td>4.480676</td>
      <td>0.003791</td>
      <td>-0.540474</td>
    </tr>
    <tr>
      <th>1</th>
      <td>34.099349</td>
      <td>2.240627</td>
      <td>-0.047215</td>
      <td>-1.842016</td>
      <td>-0.847182</td>
      <td>-0.389802</td>
      <td>-0.111497</td>
      <td>-2.765864</td>
      <td>-2.446336</td>
      <td>-0.447575</td>
      <td>...</td>
      <td>0.798257</td>
      <td>1.826385</td>
      <td>0.221681</td>
      <td>2.458930</td>
      <td>5.712048</td>
      <td>-0.236144</td>
      <td>2.160096</td>
      <td>4.133212</td>
      <td>-0.054797</td>
      <td>10.323832</td>
    </tr>
    <tr>
      <th>2</th>
      <td>32.481750</td>
      <td>2.785222</td>
      <td>-0.047215</td>
      <td>-2.489083</td>
      <td>0.720136</td>
      <td>-1.188099</td>
      <td>-0.501012</td>
      <td>-3.213930</td>
      <td>-2.258950</td>
      <td>-1.216194</td>
      <td>...</td>
      <td>0.859106</td>
      <td>2.192760</td>
      <td>-1.669444</td>
      <td>3.091403</td>
      <td>12.897608</td>
      <td>-0.215380</td>
      <td>1.741864</td>
      <td>3.757071</td>
      <td>-0.011310</td>
      <td>-9.057812</td>
    </tr>
    <tr>
      <th>3</th>
      <td>34.457911</td>
      <td>1.190100</td>
      <td>-0.047215</td>
      <td>-1.201301</td>
      <td>-1.893444</td>
      <td>-0.217819</td>
      <td>-0.681230</td>
      <td>-2.466085</td>
      <td>-1.134824</td>
      <td>-1.307211</td>
      <td>...</td>
      <td>0.386158</td>
      <td>1.437928</td>
      <td>-0.062408</td>
      <td>2.459207</td>
      <td>4.788274</td>
      <td>-0.172863</td>
      <td>1.685140</td>
      <td>3.760042</td>
      <td>-0.049314</td>
      <td>11.777028</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32.185869</td>
      <td>2.298772</td>
      <td>-0.047215</td>
      <td>-1.554065</td>
      <td>-0.884244</td>
      <td>1.800027</td>
      <td>-0.027299</td>
      <td>-2.574601</td>
      <td>-1.991742</td>
      <td>-0.659893</td>
      <td>...</td>
      <td>-0.148268</td>
      <td>1.202387</td>
      <td>-0.822042</td>
      <td>1.747517</td>
      <td>3.763874</td>
      <td>-0.237071</td>
      <td>2.108391</td>
      <td>3.923432</td>
      <td>-0.041574</td>
      <td>15.185345</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can write this out to a csv or analyze it in memory like a typical pandas dataframes:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trace_dataframe</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sigma2       32.191602
Tau2          1.875002
Lambda        0.590718
Alphas_0     -1.511708
Alphas_1     -0.091938
Alphas_2     -0.034680
Alphas_3      0.119041
Alphas_4     -2.194331
Alphas_5     -0.865278
Alphas_6     -0.313610
Alphas_7      1.154932
Alphas_8      0.196744
Alphas_9     -0.106956
Alphas_10     1.071748
Alphas_11     0.372573
Alphas_12     0.264176
Alphas_13     1.943292
Alphas_14    -0.562918
Alphas_15     2.167571
Betas_0       8.178978
Betas_1      -0.261140
Betas_2       1.793932
Betas_3       3.974848
Betas_4      -0.006224
Betas_5       2.013807
dtype: float64</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The second is a method to plot the traces:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/lw17329/anaconda/envs/ana/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_25_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The trace object can be sliced by (chain, parameter, index) tuples, or any subset thereof.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;Lambda&#39;</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="c1">#last 4 draws of lambda</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.72462283, 0.72462283, 0.34900417, 0.34900417])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="p">[[</span><span class="s1">&#39;Tau2&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigma2&#39;</span><span class="p">],</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="c1">#the first 2 variance parameters</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Tau2&#39;: [0.923435131177113, 2.240627234434746],
 &#39;Sigma2&#39;: [31.23339280347621, 34.09934860150135]}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We only ran a single chain, so the first index is assumed to be zero. You can run more than one chain in parallel, using the builtin python <code>multiprocessing</code> library:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                      <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                      <span class="c1">#run 3 chains</span>
                                      <span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                      <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">tuning</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                                                   <span class="n">adapt_step</span><span class="o">=</span><span class="mf">1.01</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 5000/5000 [01:07&lt;00:00, 73.57it/s]
100%|██████████| 5000/5000 [01:09&lt;00:00, 72.38it/s] 
100%|██████████| 5000/5000 [01:10&lt;00:00, 71.31it/s] 
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">trace</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Betas&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#the last draw of Beta on the first chain. </span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 8.34392377],
       [-0.29268161],
       [ 1.85086248],
       [ 4.0572153 ],
       [ 0.12809572],
       [-2.34258149]])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">trace</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Betas&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#the last draw of Beta on the second chain</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 8.12849684],
       [-0.26135619],
       [ 1.43630595],
       [ 4.01361537],
       [ 0.15468895],
       [-4.25558513]])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>and the chain plotting works also for the multi-chain traces. In addition, there are quite a few traceplot options, and all the plots are returned by the methods as matplotlib objects, so they can also be saved using <code>plt.savefig()</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">burn</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;SMA of Homicide Rate in Southern US Counties&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1">#plt.savefig(&#39;trace.png&#39;) #saves to a file called &quot;trace.png&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_34_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">burn</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="s1">&#39;Lambda&#39;</span><span class="p">)</span> <span class="c1">#A negative burn-in works like negative indexing in Python &amp; R </span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;First 100 iterations of $\lambda$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">y</span><span class="o">=.</span><span class="mi">02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1">#so this plots Lambda in the first 100 iterations. </span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_35_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To get stuff like posterior quantiles, you can use the attendant pandas dataframe functionality, like <code>describe</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sigma2</th>
      <th>Tau2</th>
      <th>Lambda</th>
      <th>Alphas_0</th>
      <th>Alphas_1</th>
      <th>Alphas_2</th>
      <th>Alphas_3</th>
      <th>Alphas_4</th>
      <th>Alphas_5</th>
      <th>Alphas_6</th>
      <th>...</th>
      <th>Alphas_12</th>
      <th>Alphas_13</th>
      <th>Alphas_14</th>
      <th>Alphas_15</th>
      <th>Betas_0</th>
      <th>Betas_1</th>
      <th>Betas_2</th>
      <th>Betas_3</th>
      <th>Betas_4</th>
      <th>Betas_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>...</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>32.191602</td>
      <td>1.875002</td>
      <td>0.590718</td>
      <td>-1.511708</td>
      <td>-0.091938</td>
      <td>-0.034680</td>
      <td>0.119041</td>
      <td>-2.194331</td>
      <td>-0.865278</td>
      <td>-0.313610</td>
      <td>...</td>
      <td>0.264176</td>
      <td>1.943292</td>
      <td>-0.562918</td>
      <td>2.167571</td>
      <td>8.178978</td>
      <td>-0.261140</td>
      <td>1.793932</td>
      <td>3.974848</td>
      <td>-0.006224</td>
      <td>2.013807</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.215098</td>
      <td>1.109614</td>
      <td>0.310978</td>
      <td>0.851727</td>
      <td>1.316852</td>
      <td>0.994013</td>
      <td>0.741269</td>
      <td>0.711876</td>
      <td>0.824202</td>
      <td>0.845083</td>
      <td>...</td>
      <td>0.766177</td>
      <td>0.721764</td>
      <td>0.841160</td>
      <td>0.834297</td>
      <td>3.238247</td>
      <td>0.078861</td>
      <td>0.202619</td>
      <td>0.229363</td>
      <td>0.086044</td>
      <td>9.466125</td>
    </tr>
    <tr>
      <th>min</th>
      <td>28.402067</td>
      <td>0.191395</td>
      <td>-0.559725</td>
      <td>-4.727676</td>
      <td>-5.917587</td>
      <td>-3.671202</td>
      <td>-3.125425</td>
      <td>-4.846071</td>
      <td>-4.800286</td>
      <td>-3.748046</td>
      <td>...</td>
      <td>-3.088506</td>
      <td>-0.282006</td>
      <td>-3.737387</td>
      <td>-0.651108</td>
      <td>-1.523421</td>
      <td>-0.567038</td>
      <td>1.083104</td>
      <td>3.093189</td>
      <td>-0.329770</td>
      <td>-29.672208</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>31.350144</td>
      <td>1.131752</td>
      <td>0.396936</td>
      <td>-2.059361</td>
      <td>-0.923023</td>
      <td>-0.692784</td>
      <td>-0.382492</td>
      <td>-2.664186</td>
      <td>-1.400970</td>
      <td>-0.882462</td>
      <td>...</td>
      <td>-0.243498</td>
      <td>1.435780</td>
      <td>-1.129984</td>
      <td>1.588522</td>
      <td>5.942375</td>
      <td>-0.313919</td>
      <td>1.658467</td>
      <td>3.822273</td>
      <td>-0.063075</td>
      <td>-4.347806</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>32.154740</td>
      <td>1.613698</td>
      <td>0.652983</td>
      <td>-1.480018</td>
      <td>-0.099072</td>
      <td>-0.078723</td>
      <td>0.084165</td>
      <td>-2.191222</td>
      <td>-0.870115</td>
      <td>-0.329271</td>
      <td>...</td>
      <td>0.245405</td>
      <td>1.902598</td>
      <td>-0.552477</td>
      <td>2.149598</td>
      <td>8.184837</td>
      <td>-0.260328</td>
      <td>1.794327</td>
      <td>3.974249</td>
      <td>-0.004559</td>
      <td>2.020761</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>33.023853</td>
      <td>2.324573</td>
      <td>0.856933</td>
      <td>-0.939373</td>
      <td>0.718350</td>
      <td>0.599587</td>
      <td>0.583585</td>
      <td>-1.722762</td>
      <td>-0.313782</td>
      <td>0.226628</td>
      <td>...</td>
      <td>0.760613</td>
      <td>2.404884</td>
      <td>-0.009692</td>
      <td>2.697399</td>
      <td>10.406652</td>
      <td>-0.209999</td>
      <td>1.929081</td>
      <td>4.129607</td>
      <td>0.049533</td>
      <td>8.396030</td>
    </tr>
    <tr>
      <th>max</th>
      <td>36.857707</td>
      <td>16.142846</td>
      <td>0.996376</td>
      <td>1.885945</td>
      <td>5.544127</td>
      <td>4.107627</td>
      <td>2.975758</td>
      <td>0.513466</td>
      <td>1.952173</td>
      <td>3.301225</td>
      <td>...</td>
      <td>3.775299</td>
      <td>4.693092</td>
      <td>2.795567</td>
      <td>5.473443</td>
      <td>21.099968</td>
      <td>0.063420</td>
      <td>2.660798</td>
      <td>4.763580</td>
      <td>0.346991</td>
      <td>31.900158</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 25 columns</p>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is also a <code>trace.summarize</code> function that will compute various things contained in <code>spvcm.diagnostics</code> on the chain. It takes a while for large chains, because the <code>statsmodels.tsa.AR</code> estimator is much slower than the <code>ar</code> estimator in <code>R</code>. If you have rpy2 installed <em>and</em> <code>CODA</code> installed in your R environment, I attempt to use R directly.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">summarize</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/lw17329/Dropbox/dev/spvcm/spvcm/abstracts.py:467: UserWarning: Computing effective sample size may take a while due to statsmodels.tsa.AR.
  return summarize(trace=self, level=level)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>mean</th>
      <th>HPD_low</th>
      <th>median</th>
      <th>HPD_high</th>
      <th>std</th>
      <th>N_iters</th>
      <th>N_effective</th>
      <th>AR_loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">Chain_0</th>
      <th>Sigma2</th>
      <td>32.191602</td>
      <td>29.907175</td>
      <td>32.154740</td>
      <td>34.637546</td>
      <td>1.215098</td>
      <td>5000</td>
      <td>4788</td>
      <td>0.0424</td>
    </tr>
    <tr>
      <th>Tau2</th>
      <td>1.875002</td>
      <td>0.363706</td>
      <td>1.613698</td>
      <td>3.967562</td>
      <td>1.109614</td>
      <td>5000</td>
      <td>1156</td>
      <td>0.7688</td>
    </tr>
    <tr>
      <th>Lambda</th>
      <td>0.590718</td>
      <td>-0.010077</td>
      <td>0.652983</td>
      <td>0.988580</td>
      <td>0.310978</td>
      <td>5000</td>
      <td>243</td>
      <td>0.9514</td>
    </tr>
    <tr>
      <th>Alphas_0</th>
      <td>-1.511708</td>
      <td>-3.261126</td>
      <td>-1.480018</td>
      <td>0.112208</td>
      <td>0.851727</td>
      <td>5000</td>
      <td>558</td>
      <td>0.8884</td>
    </tr>
    <tr>
      <th>Alphas_1</th>
      <td>-0.091938</td>
      <td>-2.717617</td>
      <td>-0.099072</td>
      <td>2.510040</td>
      <td>1.316852</td>
      <td>5000</td>
      <td>2415</td>
      <td>0.5170</td>
    </tr>
    <tr>
      <th>Alphas_2</th>
      <td>-0.034680</td>
      <td>-1.939546</td>
      <td>-0.078723</td>
      <td>1.956138</td>
      <td>0.994013</td>
      <td>5000</td>
      <td>871</td>
      <td>0.8258</td>
    </tr>
    <tr>
      <th>Alphas_3</th>
      <td>0.119041</td>
      <td>-1.240382</td>
      <td>0.084165</td>
      <td>1.660025</td>
      <td>0.741269</td>
      <td>5000</td>
      <td>419</td>
      <td>0.9162</td>
    </tr>
    <tr>
      <th>Alphas_4</th>
      <td>-2.194331</td>
      <td>-3.625861</td>
      <td>-2.191222</td>
      <td>-0.832241</td>
      <td>0.711876</td>
      <td>5000</td>
      <td>419</td>
      <td>0.9162</td>
    </tr>
    <tr>
      <th>Alphas_5</th>
      <td>-0.865278</td>
      <td>-2.595160</td>
      <td>-0.870115</td>
      <td>0.644972</td>
      <td>0.824202</td>
      <td>5000</td>
      <td>398</td>
      <td>0.9204</td>
    </tr>
    <tr>
      <th>Alphas_6</th>
      <td>-0.313610</td>
      <td>-1.913203</td>
      <td>-0.329271</td>
      <td>1.459151</td>
      <td>0.845083</td>
      <td>5000</td>
      <td>303</td>
      <td>0.9394</td>
    </tr>
    <tr>
      <th>Alphas_7</th>
      <td>1.154932</td>
      <td>-0.462574</td>
      <td>1.116507</td>
      <td>2.936222</td>
      <td>0.874826</td>
      <td>5000</td>
      <td>484</td>
      <td>0.9032</td>
    </tr>
    <tr>
      <th>Alphas_8</th>
      <td>0.196744</td>
      <td>-1.471783</td>
      <td>0.157301</td>
      <td>1.876040</td>
      <td>0.875341</td>
      <td>5000</td>
      <td>237</td>
      <td>0.9526</td>
    </tr>
    <tr>
      <th>Alphas_9</th>
      <td>-0.106956</td>
      <td>-1.671481</td>
      <td>-0.119013</td>
      <td>1.397663</td>
      <td>0.780549</td>
      <td>5000</td>
      <td>447</td>
      <td>0.9106</td>
    </tr>
    <tr>
      <th>Alphas_10</th>
      <td>1.071748</td>
      <td>-0.629166</td>
      <td>1.058539</td>
      <td>2.726753</td>
      <td>0.861175</td>
      <td>5000</td>
      <td>497</td>
      <td>0.9006</td>
    </tr>
    <tr>
      <th>Alphas_11</th>
      <td>0.372573</td>
      <td>-1.162294</td>
      <td>0.366974</td>
      <td>1.930433</td>
      <td>0.799864</td>
      <td>5000</td>
      <td>409</td>
      <td>0.9182</td>
    </tr>
    <tr>
      <th>Alphas_12</th>
      <td>0.264176</td>
      <td>-1.130617</td>
      <td>0.245405</td>
      <td>1.871470</td>
      <td>0.766177</td>
      <td>5000</td>
      <td>484</td>
      <td>0.9032</td>
    </tr>
    <tr>
      <th>Alphas_13</th>
      <td>1.943292</td>
      <td>0.589564</td>
      <td>1.902598</td>
      <td>3.395755</td>
      <td>0.721764</td>
      <td>5000</td>
      <td>249</td>
      <td>0.9502</td>
    </tr>
    <tr>
      <th>Alphas_14</th>
      <td>-0.562918</td>
      <td>-2.205367</td>
      <td>-0.552477</td>
      <td>1.125969</td>
      <td>0.841160</td>
      <td>5000</td>
      <td>510</td>
      <td>0.8980</td>
    </tr>
    <tr>
      <th>Alphas_15</th>
      <td>2.167571</td>
      <td>0.555624</td>
      <td>2.149598</td>
      <td>3.804761</td>
      <td>0.834297</td>
      <td>5000</td>
      <td>409</td>
      <td>0.9182</td>
    </tr>
    <tr>
      <th>Betas_0</th>
      <td>8.178978</td>
      <td>1.900055</td>
      <td>8.184837</td>
      <td>14.474289</td>
      <td>3.238247</td>
      <td>5000</td>
      <td>2668</td>
      <td>0.4664</td>
    </tr>
    <tr>
      <th>Betas_1</th>
      <td>-0.261140</td>
      <td>-0.410947</td>
      <td>-0.260328</td>
      <td>-0.101738</td>
      <td>0.078861</td>
      <td>5000</td>
      <td>2513</td>
      <td>0.4974</td>
    </tr>
    <tr>
      <th>Betas_2</th>
      <td>1.793932</td>
      <td>1.384019</td>
      <td>1.794327</td>
      <td>2.176764</td>
      <td>0.202619</td>
      <td>5000</td>
      <td>4310</td>
      <td>0.1380</td>
    </tr>
    <tr>
      <th>Betas_3</th>
      <td>3.974848</td>
      <td>3.508665</td>
      <td>3.974249</td>
      <td>4.408589</td>
      <td>0.229363</td>
      <td>5000</td>
      <td>3408</td>
      <td>0.3184</td>
    </tr>
    <tr>
      <th>Betas_4</th>
      <td>-0.006224</td>
      <td>-0.178816</td>
      <td>-0.004559</td>
      <td>0.162295</td>
      <td>0.086044</td>
      <td>5000</td>
      <td>418</td>
      <td>0.9164</td>
    </tr>
    <tr>
      <th>Betas_5</th>
      <td>2.013807</td>
      <td>-16.324642</td>
      <td>2.020761</td>
      <td>20.862976</td>
      <td>9.466125</td>
      <td>5000</td>
      <td>4064</td>
      <td>0.1872</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, 5000 iterations, but many parameters have an effective sample size that's much less than this. There's debate about whether it's necesasry to thin these samples in accordance with the effective size, and I think you should thin your sample to the effective size and see if it affects your HPD/Standard Errorrs.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The existing python packages for MCMC diagnostics were incorrect. So, I've implemented many of the diagnostics from <code>CODA</code>, and have verified that the diagnostics comport with <code>CODA</code> diagnostics. One can also use <code>numpy</code> &amp; <code>statsmodels</code> functions. I'll show some types of analysis.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.api</span> <span class="kn">import</span> <span class="n">tsa</span>
<span class="c1">#if you don&#39;t have it, try removing the comment and:</span>
<span class="c1">#! pip install statsmodels</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For example, a plot of the partial autocorrelation in $\lambda$, the upper-level spatial moving average parameter, over the last half of the chain is:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tsa</span><span class="o">.</span><span class="n">pacf</span><span class="p">(</span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;Lambda&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">2500</span><span class="p">:]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fcfe122d7f0&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_45_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, the chain is close-to-first order:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tsa</span><span class="o">.</span><span class="n">pacf</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1.        , 0.90178845, 0.03398422])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We could do this for many parameters, too. An Autocorrelation/Partial Autocorrelation plot can be made of the marginal effects by:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">betas</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Beta&#39;</span><span class="p">)]</span>
<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">betas</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">betas</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tsa</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tsa</span><span class="o">.</span><span class="n">pacf</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span> <span class="c1">#the pacf plots take a while</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">col</span> <span class="o">+</span><span class="s1">&#39; (ACF)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;(PACF)&#39;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_49_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As far as the builtin diagnostics for convergence and simulation quality, the <code>diagnostics</code> module exposes a few things:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Geweke statistics for differences in means between chain components:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gstats</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">geweke</span><span class="p">(</span><span class="n">vcsma</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="s1">&#39;Tau2&#39;</span><span class="p">)</span> <span class="c1">#takes a while</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gstats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[{&#39;Tau2&#39;: array([-0.70525936, -0.86465127, -0.66491713, -1.10260496, -0.85742401,
       -0.57409951, -0.41226321, -1.20085802, -1.45556743, -1.50305192,
       -1.36917624, -1.7651641 , -1.62251801, -1.91653818, -2.95959606,
       -3.25223318, -3.00471879, -1.58320811, -1.49846186, -1.84009018,
       -1.94378006, -1.55312447, -1.74487948, -1.77123135, -1.25633365,
       -1.75786086, -0.88990747, -0.68509239, -0.66391378,  0.32228814,
        0.98220296,  1.03257125,  0.93549226,  0.88218052,  0.41084557,
        0.80814834, -0.23443594,  0.2413701 , -0.73956236, -0.77123872,
       -0.74954084,  0.1017357 , -0.141298  , -0.11990577,  1.05561834,
        1.04085492,  1.58169489,  1.69289289,  2.08680592,  1.98418018])}]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Typically, this means the chain is converged at the given "bin" count if the line stays within $\pm2$. The geweke statistic is a test of differences in means between the given chunk of the chain and the remaining chain. If it's outside of +/- 2 in the early part of the chain, you should discard observations early in the chain. If you get extreme values of these statistics throughout, you need to keep running the chain.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gstats</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;Tau2&#39;</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7fcfe12a9eb8&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_54_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also compute Monte Carlo Standard Errors like in the <code>mcse</code> R package, which represent the intrinsic error contained in the estimate:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spvcm</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">mcse</span><span class="p">(</span><span class="n">vcsma</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Tau2&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigma2&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Sigma2&#39;: 0.01727439579905615, &#39;Tau2&#39;: 0.031562453419661775}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another handy statistic is the Partial Scale Reduction factor, which measures of how likely a set of chains run in parallel have converged to the same stationary distribution. It provides the difference in variance between between chains vs. within chains.</p>
<p>If these are significantly larger than one (say, 1.5), the chain probably has not converged. Being marginally below $1$ is fine, too.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spvcm</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">psrf</span><span class="p">(</span><span class="n">vcsma_p</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Tau2&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigma2&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Tau2&#39;: 1.0077401382404925, &#39;Sigma2&#39;: 0.9998141761817744}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Highest posterior density intervals provide a kind of interval estimate for parameters in Bayesian models:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spvcm</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">hpd_interval</span><span class="p">(</span><span class="n">vcsma</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Betas&#39;</span><span class="p">,</span> <span class="s1">&#39;Lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigma2&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Betas&#39;: [(1.9000548460393478, 14.474288717664574),
  (-0.41094673834079987, -0.10173775264997412),
  (1.384018831652215, 2.1767635687081506),
  (3.508665394133376, 4.408589008319321),
  (-0.17881562058023562, 0.16229519966707567),
  (-16.32464174373274, 20.862975934687753)],
 &#39;Sigma2&#39;: (29.9071748836272, 34.63754603742357),
 &#39;Lambda&#39;: (-0.010077055754050324, 0.9885795446636961)}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sometimes, you want to apply arbitrary functions to each parameter trace. To do this, I've written a <code>map</code> function that works like the python builtin <code>map</code>. For example, if you wanted to get arbitrary percentiles from the chain:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">,</span> 
                <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;Tau2&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigma2&#39;</span><span class="p">],</span>
                <span class="c1">#arguments to pass to the function go last</span>
                <span class="n">q</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">])</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;Lambda&#39;: array([0.39693634, 0.65298256, 0.85693311]),
  &#39;Tau2&#39;: array([1.13175212, 1.61369846, 2.32457265]),
  &#39;Sigma2&#39;: array([31.35014374, 32.15473988, 33.02385302])}]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In addition, you can pop the trace results pretty simply to a <code>.csv</code> file and analyze it elsewhere, like if you want to use use the <code>coda</code> Bayesian Diagnostics package in <code>R</code>.</p>
<p>To write out a model to a csv, you can use:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./model_run.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And, you can even load traces from csvs:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">abstracts</span><span class="o">.</span><span class="n">Trace</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="s1">&#39;./model_run.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">varnames</span><span class="p">)</span>
<span class="n">tr</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Tau2&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;Lambda&#39;, &#39;Sigma2&#39;, &#39;Tau2&#39;, &#39;Alphas&#39;, &#39;Betas&#39;]
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/lw17329/anaconda/envs/ana/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&lt;Figure size 576x144 with 2 Axes&gt;,
 array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fcfe12fd5f8&gt;,
         &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fcfe12c5198&gt;]],
       dtype=object))</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_66_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Working-with-models:-draw-and-sample">Working with models: <code>draw</code> and <code>sample</code><a class="anchor-link" href="#Working-with-models:-draw-and-sample"> </a></h1><p>These two functions are used to call the underlying Gibbs sampler. They take no arguments, and operate on the sampler in place. <code>draw</code> provides a single new sample:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And sample steps forward an arbitrary number of times:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 10/10 [00:00&lt;00:00, 150.30it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point, we did 5000 initial samples and 11 extra samples. Thus:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">cycles</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>5011</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Parallel models can suspend/resume sampling too:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 10/10 [00:00&lt;00:00, 80.38it/s]
100%|██████████| 10/10 [00:00&lt;00:00, 43.91it/s]
100%|██████████| 10/10 [00:00&lt;00:00, 53.23it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma_p</span><span class="o">.</span><span class="n">cycles</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>5010</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Under the hood, it's the <code>draw</code> method that actually ends up calling one run of <code>model._iteration</code>, which is where the actual statistical code lives. Then, it updates all <code>model.traced_params</code> by adding their current value in <code>model.state</code> to <code>model.trace.</code> In addition, <code>model._finalize</code> is called the first time sampling is run, which computes some of the constants &amp; derived quantities that save computing time.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Working-with-models:--state">Working with models:  <code>state</code><a class="anchor-link" href="#Working-with-models:--state"> </a></h1><p>This is the collection of current values in the sampler. To be efficient, Gibbs sampling must keep around some of the computations used in the simulation, since sometimes the same terms show up in different conditional posteriors. So, the current values of the sampler are stored in <code>state</code>.</p>
<p>All of the following are tracked in the state:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vcsma</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>dict_keys([&#39;X&#39;, &#39;Y&#39;, &#39;M&#39;, &#39;W&#39;, &#39;Delta&#39;, &#39;N&#39;, &#39;J&#39;, &#39;p&#39;, &#39;Sigma2_a0&#39;, &#39;Sigma2_b0&#39;, &#39;Betas_cov0&#39;, &#39;Betas_mean0&#39;, &#39;Tau2_a0&#39;, &#39;Tau2_b0&#39;, &#39;Log_Lambda0&#39;, &#39;Log_Rho0&#39;, &#39;Rho_min&#39;, &#39;Rho_max&#39;, &#39;Lambda_min&#39;, &#39;Lambda_max&#39;, &#39;Betas&#39;, &#39;Alphas&#39;, &#39;Sigma2&#39;, &#39;Tau2&#39;, &#39;Rho&#39;, &#39;Lambda&#39;, &#39;Psi_1&#39;, &#39;Psi_1i&#39;, &#39;Psi_2&#39;, &#39;Psi_2i&#39;, &#39;In&#39;, &#39;Ij&#39;, &#39;Betas_cov0i&#39;, &#39;Betas_covm&#39;, &#39;Sigma2_an&#39;, &#39;Tau2_an&#39;, &#39;PsiRhoi&#39;, &#39;PsiLambdai&#39;, &#39;XtX&#39;, &#39;DeltatDelta&#39;, &#39;DeltaAlphas&#39;, &#39;XBetas&#39;, &#39;initial_values&#39;])
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you want to track how something (maybe a hyperparameter) changes over sampling, you can pass <code>extra_traced_params</code> to the model declaration:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                      <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                      <span class="n">n_samples</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> 
                                      <span class="n">extra_traced_params</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DeltaAlphas&#39;</span><span class="p">],</span>
                                      <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">tuning</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">adapt_step</span><span class="o">=</span><span class="mf">1.01</span><span class="p">))</span>
<span class="n">example</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">varnames</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 250/250 [00:00&lt;00:00, 322.83it/s]
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Alphas&#39;, &#39;Betas&#39;, &#39;Sigma2&#39;, &#39;Tau2&#39;, &#39;Lambda&#39;, &#39;DeltaAlphas&#39;]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="configs"><code>configs</code><a class="anchor-link" href="#configs"> </a></h1><p>this is where configuration options for the various MCMC steps are stored. For multilevel variance components models, these are called $\rho$ for the lower-level error parameter and $\lambda$ for the upper-level parameter. Two exact sampling methods are implemented, Metropolis sampling &amp; Slice sampling.</p>
<p>Each MCMC step has its own config:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">configs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Rho&#39;: &lt;spvcm.steps.Metropolis at 0x7fcfe1438780&gt;,
 &#39;Lambda&#39;: &lt;spvcm.steps.Metropolis at 0x7fcfe1438828&gt;}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since <code>vcsma</code> is an upper-level-only model, the <code>Rho</code> config is skipped. But, we can look at the <code>Lambda</code> config. The number of accepted <code>lambda</code> draws is contained in :</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">accepted</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>725</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>so, the acceptance rate is</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">accepted</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">vcsma</span><span class="o">.</span><span class="n">cycles</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.14468170025942925</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Also, if you want to get verbose output from the metropolis sampler, there is a "debug" flag:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                      <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                      <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                                      <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">tuning</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> 
                                                   <span class="n">adapt_step</span><span class="o">=</span><span class="mf">1.01</span><span class="p">,</span> 
                                                   <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 500/500 [00:02&lt;00:00, 197.81it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which stores the information about each iteration in a list, accessible from <code>model.configs.&lt;parameter&gt;._cache</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">_cache</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#let&#39;s only look at the last one</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;jump&#39;: 2.1374234835161063,
 &#39;current_logp&#39;: array([-8.76422011]),
 &#39;new_logp&#39;: array([-8.76422011]),
 &#39;accepted&#39;: False}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Configuration of the MCMC steps is done using the <code>config</code> options dictionary, like done in <code>spBayes</code> in <code>R</code>. The actual configuration classes exist in spvcm.steps:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">spvcm.steps</span> <span class="kn">import</span> <span class="n">Metropolis</span><span class="p">,</span> <span class="n">Slice</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most of the common options are:</p>
<h3 id="Metropolis">Metropolis<a class="anchor-link" href="#Metropolis"> </a></h3><ul>
<li><code>jump</code>: the starting standard deviation of the proposal distribution</li>
<li><code>tuning</code>: the number of iterations to tune the scale of the proposal</li>
<li><code>ar_low</code>: the lower bound of the target acceptance rate range</li>
<li><code>ar_hi</code>: the upper bound of the target acceptance rate range</li>
<li><code>adapt_step</code>: a number (bigger than 1) that will be used to modify the jump in order to keep the acceptance rate betwen <code>ar_lo</code> and <code>ar_hi</code>. Values much larger than <code>1</code> result in much more dramatic tuning. </li>
</ul>
<h3 id="Slice">Slice<a class="anchor-link" href="#Slice"> </a></h3><ul>
<li><code>width</code>: starting width of the level set</li>
<li><code>adapt</code>: number of previous slices use in the weighted average for the next slice. If <code>0</code>, the <code>width</code> is not dynamically tuned. </li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                      <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                      <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                                      <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">tuning</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> 
                                                   <span class="n">adapt_step</span><span class="o">=</span><span class="mf">1.01</span><span class="p">,</span> 
                                      <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ar_low</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">ar_hi</span><span class="o">=.</span><span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 500/500 [00:02&lt;00:00, 177.09it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">ar_hi</span><span class="p">,</span> <span class="n">example</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">ar_low</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.4, 0.1)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example_slicer</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">upper_level</span><span class="o">.</span><span class="n">Upper_SMA</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                             <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                             <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                                             <span class="n">configs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">Lambda_method</span><span class="o">=</span><span class="s1">&#39;slice&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 500/500 [00:06&lt;00:00, 83.21it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example_slicer</span><span class="o">.</span><span class="n">trace</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">varnames</span><span class="o">=</span><span class="s1">&#39;Lambda&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/model/spvcm/using_the_sampler_97_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example_slicer</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">adapt</span><span class="p">,</span> <span class="n">example_slicer</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">width</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0, 0.5)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Working-with-models:-customization">Working with models: customization<a class="anchor-link" href="#Working-with-models:-customization"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you're doing heavy customization, it makes the most sense to first initialize the class without sampling. We did this before when showing how the "extra_traced_params" option worked.</p>
<p>To show, let's initialize a double-level SAR-Error variance components model, but not actually draw anything.</p>
<p>To do this, you pass the option <code>n_samples=0</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span> <span class="o">=</span> <span class="n">spvcm</span><span class="o">.</span><span class="n">both_levels</span><span class="o">.</span><span class="n">SESE</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> 
                                <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span> 
                                <span class="n">n_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>0it [00:00, ?it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This sets up a two-level spatial error model with the default uninformative configuration. This means the prior precisions are all <code>I * .001*</code>, prior means are all 0, spatial parameters are set to <code>-1/(n-1)</code>, and prior scale factors are set arbitrarily.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Configs">Configs<a class="anchor-link" href="#Configs"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Options are set by assgning to the relevant property in <code>model.configs</code>.</p>
<p>The model configuration object is another dictionary with a few special methods.</p>
<p>Configuration options are stored for each parameter separately:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">configs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;Rho&#39;: &lt;spvcm.steps.Metropolis at 0x7fcfe13004a8&gt;,
 &#39;Lambda&#39;: &lt;spvcm.steps.Metropolis at 0x7fcfe13002b0&gt;}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, for example, if we wanted to turn off adaptation in the upper-level parameter, and fix the Metrpolis jump variance to <code>.25</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">max_tuning</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">vcsese</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">Lambda</span><span class="o">.</span><span class="n">jump</span>  <span class="o">=</span> <span class="o">.</span><span class="mi">25</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Priors">Priors<a class="anchor-link" href="#Priors"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another thing that might be interesting (though not "bayesian") would be to fix the prior mean of $\beta$ to the OLS estimates. One way this could be done would be to pull the <code>Delta</code> matrix out from the state, and estimate:
$$ Y = X\beta + \Delta Z + \epsilon $$
using <code>PySAL</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Delta</span> <span class="o">=</span> <span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Delta</span>
<span class="n">DeltaZ</span> <span class="o">=</span> <span class="n">Delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Betas_mean0</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">spreg</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">DeltaZ</span><span class="p">)))</span><span class="o">.</span><span class="n">betas</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Starting-Values">Starting Values<a class="anchor-link" href="#Starting-Values"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you wanted to start the sampler at a given starting value, you can do so by assigning that value to the <code>Lambda</code> value in <code>state</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">=</span> <span class="o">-.</span><span class="mi">25</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sometimes, it's suggested that you start the beta vector randomly, rather than at zero. For the parallel sampling, the model starting values are adjusted to induce overdispersion in the start values.</p>
<p>You could do this manually, too:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Betas</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">p</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Spatial-Priors">Spatial Priors<a class="anchor-link" href="#Spatial-Priors"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Changing the spatial parameter priors is also done by changing their prior in state. This prior must be a function that takes a value of the parameter and return the log of the prior probability for that value.</p>
<p>For example, we could assign <code>P(\lambda) = Beta(2,1)</code> and zero if outside $(0,1)$, and asign $\rho$ a truncated $\mathcal{N}(0,.5)$ prior by first defining their functional form:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">Lambda_prior</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">val</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">val</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">Rho_prior</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">val</span> <span class="o">&gt;</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">val</span> <span class="o">&lt;</span> <span class="o">-.</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">truncnorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=.</span><span class="mi">5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then assigning to their symbols, <code>LogLambda0</code> and <code>LogRho0</code> in the state:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">LogLambda0</span> <span class="o">=</span> <span class="n">Lambda_prior</span>
<span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">LogRho0</span> <span class="o">=</span> <span class="n">Rho_prior</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Performance">Performance<a class="anchor-link" href="#Performance"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The efficiency of the sampler is contingent on the lower-level size. If we were to estimate the draw in a dual-level SAR-Error Variance Components iteration:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">timeit</span> vcsese.draw()
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>26 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To make it easy to work with the model, you can interrupt and resume sampling using keyboard interrupts (<code>ctrl-c</code> or the <code>stop</code> button in the notebook).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span> vcsese.sample(100)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 100/100 [00:02&lt;00:00, 37.97it/s]</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 10.4 s, sys: 148 ms, total: 10.5 s
Wall time: 2.64 s
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 10/10 [00:00&lt;00:00, 28.37it/s]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Under-the-Hood">Under the Hood<a class="anchor-link" href="#Under-the-Hood"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Package-Structure">Package Structure<a class="anchor-link" href="#Package-Structure"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most of the tools in the package are stored in relevant python files in the top level or a dedicated subfolder. Explaining a few:</p>
<ul>
<li><code>abstracts.py</code> - the abstract class machinery to iterate over a sampling loop. This is where the classes are defined, like <code>Trace</code>, <code>Sampler_Mixin</code>, or <code>Hashmap</code>. </li>
<li><code>plotting.py</code> - tools for plotting output</li>
<li><code>steps.py</code> - the step method definitions</li>
<li><code>verify.py</code> - like <code>user</code> checks in <code>pysal.spreg</code>, this contains a few sanity checks. </li>
<li><code>utils.py</code>- contains statistical or numerical utilities to make the computation easier, like cholesky multivariate normal sampling, more sparse utility functions, etc. </li>
<li><code>diagnostics.py</code> - all the diagnostics</li>
<li><code>priors.py</code> - definitions of alternative prior forms. Right now, this is pretty simple. </li>
<li><code>sqlite.py</code> - functions to use a sqlite database instead of an in-memory chain are defined here. </li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-implementation-of-a-Model">The implementation of a Model<a class="anchor-link" href="#The-implementation-of-a-Model"> </a></h3><p>The package is implemented so that every "model type" first sends off to the <code>spvcm.both.Base_Generic</code>, which sets up the state, trace, and priors.</p>
<p>Models are added by writing a <code>model.py</code> file and possibly a <code>sample.py</code> file. The <code>model.py</code> file defines a <code>Base/User</code> class pair (like <code>spreg</code>) that sets up the state and trace. It must define hyperparameters, and can precompute objects used in the sampling loop. The base class should inherit from <code>Sampler_Mixin</code>, which defines all of the machinery of sampling.</p>
<p>The loop through the conditional posteriors should be defined in <code>model.py</code>, in the <code>model._iteration</code> function. This should update the model state in place.</p>
<p>The model may also define a <code>_finalize</code> function which is run once before sampling.</p>
<p>So, if I write a new model, like a varying-intercept model with endogenously-lagged intercepts, I would write a <code>model.py</code> containing something like:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Base_VISAR</span><span class="p">(</span><span class="n">spvcm</span><span class="o">.</span><span class="n">generic</span><span class="o">.</span><span class="n">Base_Generic</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">membership</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Delta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">extra_traced_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1">#record extra things in state</span>
                 <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1">#sampling config</span>
                 <span class="n">priors</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># dict with prior values for params</span>
                 <span class="n">configs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># dict with configs for MCMC steps</span>
                 <span class="n">starting_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># dict with starting values</span>
                 <span class="n">truncation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># options to truncate MCMC step priors</span>
                 <span class="n">center</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># Whether to center the X,Z matrices</span>
                 <span class="n">scale</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># Whether re-scale the X,Z matrices</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Base_VISAR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                         <span class="n">membership</span><span class="o">=</span><span class="n">membership</span><span class="p">,</span>
                                         <span class="n">Delta</span><span class="o">=</span><span class="n">Delta</span><span class="p">,</span>
                                         <span class="n">n_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                                         <span class="n">priors</span><span class="o">=</span><span class="n">priors</span><span class="p">,</span> <span class="n">configs</span><span class="o">=</span><span class="n">configs</span><span class="p">,</span>
                                         <span class="n">starting_values</span><span class="o">=</span><span class="n">starting_values</span><span class="p">,</span>
                                         <span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span>
                                         <span class="n">center</span><span class="o">=</span><span class="n">center</span><span class="p">,</span>
                                         <span class="n">scale</span><span class="o">=</span><span class="n">scale</span>
                                         <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="c1"># the degrees of freedom of the variance parameter is constant</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Sigma2_an</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Sigma2_a0</span>
            <span class="o">...</span>

        <span class="k">def</span> <span class="nf">_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

            <span class="c1"># computing the values needed to sample from the conditional posteriors</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">spdot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">spdot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PsiRhoi</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span> <span class="o">/</span> <span class="n">Sigma2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">bmean0</span>
            <span class="o">...</span>
    <span class="o">...</span>
</pre></div>
<p>I've organized the directories in this project into <code>both_levels</code>, <code>upper_level</code>, <code>lower_level</code>, and <code>hierarchical</code>, which contains some of the spatially-varying coefficient models &amp; other models I'm working on that are unrelated to the multilevel variance components stuff.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since most of the <code>_iteration</code> loop is the same between models, most of the models share the same sampling code, but customize the structure of the covariance in each level. These covariance variables are stored in the <code>state.Psi_1</code>, for the lower-level covariance, and <code>state.Psi_2</code> for the upper-level covariance. Likewise, the precision functions are <code>state.Psi_1i</code> and <code>state.Psi_2i</code>.</p>
<p>For example:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Psi_1</span> <span class="c1">#lower-level covariance</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;function spvcm.utils.se_covariance(param, W, sparse=False)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsese</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Psi_2</span> <span class="c1">#upper-level covariance</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;function spvcm.utils.se_covariance(param, W, sparse=False)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Psi_2</span> <span class="c1">#upper-level covariance</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;function spvcm.utils.sma_covariance(param, W, sparse=True)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Psi_2i</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;function spvcm.utils.sma_precision(param, W, sparse=False)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vcsma</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">Psi_1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;function spvcm.utils.ind_covariance(param, W, sparse=False)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The functions that generate the covariance matrices are stored in <code>spvcm.utils</code>. They can be arbitrarily overwritten for alternative covariance specifications.</p>
<p>Thus, if we want to sample a model with a new covariance specification, then we need to define functions for the variance and precision.</p>

</div>
</div>
</div>
</div>

 


    </main>
    